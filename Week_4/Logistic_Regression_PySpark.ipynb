{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POFRGbv6QgZp"
      },
      "source": [
        "# **Logistic Regression with Mathematical Insights using PySpark ML**\n",
        "\n",
        "### **`Dr Amin Karami (PhD, FHEA, EE), UEL UK - Docklands Campus`**\n",
        "\n",
        "`E: amin.karami@ymail.com`\n",
        "\n",
        "`W: https://www.youtube.com/@AminKarami`\n",
        "\n",
        "`W: https://www.aminkarami.com`\n",
        "\n",
        "---\n",
        "\n",
        "**Learning Outcomes**:\n",
        "\n",
        "`Master Logistic Regression and Optimization`: Understand and apply Logistic Regression and Gradient Descent optimization to classify data using PySpark ML.\n",
        "\n",
        "`Data Handling Expertise`: Acquire skills in preprocessing, feature selection, and data management within a Jupyter Notebook environment for large-scale datasets.\n",
        "\n",
        "`Accuracy Assessment`: Gain proficiency in evaluating model performance with various accuracy metrics including confusion matrix, ensuring reliable classification insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7PLOpJX5G99S"
      },
      "outputs": [],
      "source": [
        "# !pip3 install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiN5XAUuQxUj"
      },
      "source": [
        "# **Step 1:** Import the required libraries and initialize SparkSession."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8V-y6jQPGyKm"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://Jareer:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>LogisticRegressionExample</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x2018a2d6fd0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "                    .appName(\"LogisticRegressionExample\") \\\n",
        "                    .master(\"local[*]\") \\\n",
        "                    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "                    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "                    .config(\"spark.executor.cores\", \"2\") \\\n",
        "                    .config(\"spark.sql.inMemoryColumnarStorage.compressed\", \"true\") \\\n",
        "                    .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD0CTmfUQ3Ub"
      },
      "source": [
        "# **Step 2:** Load and preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-TFY4zdDYR1D"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRvmZc8wqVCp"
      },
      "source": [
        "# **KDDCup Data**:\n",
        "\n",
        "The dataset contains network intrusion detection data, which is used to develop and test algorithms for detecting unauthorized access to computer networks. The KDD Cup 1999 Data has been widely used in the research community for developing and testing intrusion detection systems.\n",
        "\n",
        "URL: https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
        "\n",
        "Data Description: https://kdd.ics.uci.edu/databases/kddcup99/task.html\n",
        "\n",
        "Features: https://kdd.ics.uci.edu/databases/kddcup99/kddcup.names\n",
        "\n",
        "Labels: https://kdd.ics.uci.edu/databases/kddcup99/training_attack_types\n",
        "\n",
        "\n",
        "# Data Collection:\n",
        "\n",
        "[The full data set](https://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz) (18M; 743M Uncompressed)\n",
        "\n",
        "[A 10% subset](https://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz) (2.1M; 75M Uncompressed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YXsh_MXQXDEk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---+----+---+---+----+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-------+\n",
            "|_c0|_c1| _c2|_c3|_c4| _c5|_c6|_c7|_c8|_c9|_c10|_c11|_c12|_c13|_c14|_c15|_c16|_c17|_c18|_c19|_c20|_c21|_c22|_c23|_c24|_c25|_c26|_c27|_c28|_c29|_c30|_c31|_c32|_c33|_c34|_c35|_c36|_c37|_c38|_c39|_c40|   _c41|\n",
            "+---+---+----+---+---+----+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-------+\n",
            "|  0|tcp|http| SF|181|5450|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   8|   8|0.00|0.00|0.00|0.00|1.00|0.00|0.00|   9|   9|1.00|0.00|0.11|0.00|0.00|0.00|0.00|0.00|normal.|\n",
            "|  0|tcp|http| SF|239| 486|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   8|   8|0.00|0.00|0.00|0.00|1.00|0.00|0.00|  19|  19|1.00|0.00|0.05|0.00|0.00|0.00|0.00|0.00|normal.|\n",
            "|  0|tcp|http| SF|235|1337|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   8|   8|0.00|0.00|0.00|0.00|1.00|0.00|0.00|  29|  29|1.00|0.00|0.03|0.00|0.00|0.00|0.00|0.00|normal.|\n",
            "|  0|tcp|http| SF|219|1337|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   6|   6|0.00|0.00|0.00|0.00|1.00|0.00|0.00|  39|  39|1.00|0.00|0.03|0.00|0.00|0.00|0.00|0.00|normal.|\n",
            "|  0|tcp|http| SF|217|2032|  0|  0|  0|  0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   6|   6|0.00|0.00|0.00|0.00|1.00|0.00|0.00|  49|  49|1.00|0.00|0.02|0.00|0.00|0.00|0.00|0.00|normal.|\n",
            "+---+---+----+---+---+----+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "494021\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Load the compressed file as a text file\n",
        "df = spark.read.csv(\"kddcup.data_10_percent.gz\", header = False)\n",
        "\n",
        "# Display the DataFrame\n",
        "df.show(5)\n",
        "\n",
        "# more info\n",
        "print(df.count())\n",
        "print(df.rdd.getNumPartitions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If you wanna go ahead with the full size, repartiton it to 6 chunks.\n",
        "\n",
        "# for the 10% of data:\n",
        "df = df.repartition(2)\n",
        "df.rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLTVngDXbWCm"
      },
      "source": [
        "# Add header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UuE2dHnAbXuW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-------------+--------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+\n",
            "|duration|protocol_type| service|flag|src_bytes|dst_bytes|land|wrong_fragment|urgent|host|num_failed_logins|logged_in|num_compromised|root_shell|su_attempted|num_root|num_file_creations|num_shells|num_access_files|num_outbound_cmds|is_host_login|is_guest_login|count|srv_count|serror_rate|srv_serror_rate|rerror_rate|srv_rerror_rate|same_srv_rate|diff_srv_rate|srv_diff_host_rate|dst_host_count|dst_host_srv_count|dst_host_same_srv_rate|dst_host_diff_srv_rate|dst_host_same_src_port_rate|dst_host_srv_diff_host_rate|dst_host_serror_rate|dst_host_srv_serror_rate|dst_host_rerror_rate|dst_host_srv_rerror_rate|connection_status|\n",
            "+--------+-------------+--------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+\n",
            "|       0|          tcp|ftp_data|  SF|     7233|        0|   0|             0|     0|   0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    8|        4|       0.00|           0.00|       0.00|           0.00|         0.50|         0.38|              0.00|           255|                10|                  0.04|                  0.34|                       0.04|                       0.00|                0.00|                    0.00|                0.00|                    0.00|          normal.|\n",
            "|       0|          tcp| private| REJ|        0|        0|   0|             0|     0|   0|                0|        0|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|  137|        4|       0.00|           0.00|       1.00|           1.00|         0.03|         0.06|              0.00|           255|                 4|                  0.02|                  0.05|                       0.00|                       0.00|                0.00|                    0.00|                1.00|                    1.00|         neptune.|\n",
            "|       0|         icmp|   ecr_i|  SF|     1032|        0|   0|             0|     0|   0|                0|        0|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|  250|      250|       0.00|           0.00|       0.00|           0.00|         1.00|         0.00|              0.00|           255|               255|                  1.00|                  0.00|                       1.00|                       0.00|                0.00|                    0.00|                0.00|                    0.00|           smurf.|\n",
            "|       0|          tcp| private| REJ|        0|        0|   0|             0|     0|   0|                0|        0|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|   61|       10|       0.00|           0.00|       1.00|           1.00|         0.16|         0.08|              0.00|           255|                10|                  0.04|                  0.06|                       0.00|                       0.00|                0.00|                    0.00|                1.00|                    1.00|         neptune.|\n",
            "|       0|          tcp|    http|  SF|      328|      535|   0|             0|     0|   0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    6|        6|       0.00|           0.00|       0.00|           0.00|         1.00|         0.00|              0.00|           169|               255|                  1.00|                  0.00|                       0.01|                       0.03|                0.00|                    0.00|                0.00|                    0.00|          normal.|\n",
            "+--------+-------------+--------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = df.withColumnRenamed(\"_c0\",\"duration\") \\\n",
        "      .withColumnRenamed(\"_c1\",\"protocol_type\")\\\n",
        "      .withColumnRenamed(\"_c2\",\"service\")\\\n",
        "      .withColumnRenamed(\"_c3\",\"flag\")\\\n",
        "      .withColumnRenamed(\"_c4\",\"src_bytes\")\\\n",
        "      .withColumnRenamed(\"_c5\",\"dst_bytes\")\\\n",
        "      .withColumnRenamed(\"_c6\",\"land\")\\\n",
        "      .withColumnRenamed(\"_c7\",\"wrong_fragment\")\\\n",
        "      .withColumnRenamed(\"_c8\",\"urgent\")\\\n",
        "      .withColumnRenamed(\"_c9\",\"host\")\\\n",
        "      .withColumnRenamed(\"_c10\",\"num_failed_logins\")\\\n",
        "      .withColumnRenamed(\"_c11\",\"logged_in\")\\\n",
        "      .withColumnRenamed(\"_c12\",\"num_compromised\")\\\n",
        "      .withColumnRenamed(\"_c13\",\"root_shell\")\\\n",
        "      .withColumnRenamed(\"_c14\",\"su_attempted\")\\\n",
        "      .withColumnRenamed(\"_c15\",\"num_root\")\\\n",
        "      .withColumnRenamed(\"_c16\",\"num_file_creations\")\\\n",
        "      .withColumnRenamed(\"_c17\",\"num_shells\")\\\n",
        "      .withColumnRenamed(\"_c18\",\"num_access_files\")\\\n",
        "      .withColumnRenamed(\"_c19\",\"num_outbound_cmds\")\\\n",
        "      .withColumnRenamed(\"_c20\",\"is_host_login\")\\\n",
        "      .withColumnRenamed(\"_c21\",\"is_guest_login\")\\\n",
        "      .withColumnRenamed(\"_c22\",\"count\")\\\n",
        "      .withColumnRenamed(\"_c23\",\"srv_count\")\\\n",
        "      .withColumnRenamed(\"_c24\",\"serror_rate\")\\\n",
        "      .withColumnRenamed(\"_c25\",\"srv_serror_rate\")\\\n",
        "      .withColumnRenamed(\"_c26\",\"rerror_rate\")\\\n",
        "      .withColumnRenamed(\"_c27\",\"srv_rerror_rate\")\\\n",
        "      .withColumnRenamed(\"_c28\",\"same_srv_rate\")\\\n",
        "      .withColumnRenamed(\"_c29\",\"diff_srv_rate\")\\\n",
        "      .withColumnRenamed(\"_c30\",\"srv_diff_host_rate\")\\\n",
        "      .withColumnRenamed(\"_c31\",\"dst_host_count\")\\\n",
        "      .withColumnRenamed(\"_c32\",\"dst_host_srv_count\")\\\n",
        "      .withColumnRenamed(\"_c33\",\"dst_host_same_srv_rate\")\\\n",
        "      .withColumnRenamed(\"_c34\",\"dst_host_diff_srv_rate\")\\\n",
        "      .withColumnRenamed(\"_c35\",\"dst_host_same_src_port_rate\")\\\n",
        "      .withColumnRenamed(\"_c36\",\"dst_host_srv_diff_host_rate\")\\\n",
        "      .withColumnRenamed(\"_c37\",\"dst_host_serror_rate\")\\\n",
        "      .withColumnRenamed(\"_c38\",\"dst_host_srv_serror_rate\")\\\n",
        "      .withColumnRenamed(\"_c39\",\"dst_host_rerror_rate\")\\\n",
        "      .withColumnRenamed(\"_c40\",\"dst_host_srv_rerror_rate\")\\\n",
        "      .withColumnRenamed(\"_c41\",\"connection_status\")\n",
        "\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_L4jFZOc3k9"
      },
      "source": [
        "# Check the Binary labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dFYX4JHDc65k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|connection_status|\n",
            "+-----------------+\n",
            "|     warezmaster.|\n",
            "|           smurf.|\n",
            "|             pod.|\n",
            "|            nmap.|\n",
            "|            imap.|\n",
            "|    guess_passwd.|\n",
            "|         ipsweep.|\n",
            "|       portsweep.|\n",
            "|           satan.|\n",
            "|            land.|\n",
            "|      loadmodule.|\n",
            "|       ftp_write.|\n",
            "| buffer_overflow.|\n",
            "|         rootkit.|\n",
            "|     warezclient.|\n",
            "|        teardrop.|\n",
            "|            perl.|\n",
            "|             phf.|\n",
            "|        multihop.|\n",
            "|         neptune.|\n",
            "|            back.|\n",
            "|             spy.|\n",
            "|          normal.|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"connection_status\").distinct().show(30)\n",
        "\n",
        "#  Show the last 5 values of connection_status\n",
        "# df.select(\"connection_status\").distinct().orderBy(\"connection_status\", ascending=False).limit(5).show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|label|\n",
            "+-----+\n",
            "|    1|\n",
            "|    0|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "df = df.withColumn(\"label\", when(df[\"connection_status\"] != 'normal.', 1).otherwise(0))\n",
        "\n",
        "df.select(\"label\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USekfhiFfQcf"
      },
      "source": [
        "# Count the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EHH5gbTBfTRE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|label| count|\n",
            "+-----+------+\n",
            "|    1|396743|\n",
            "|    0| 97278|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupBy(\"label\").count().show()\n",
        "\n",
        "# ~20% normal traffic\n",
        "# ~80% attack traffic\n",
        "\n",
        "\n",
        "# dealing with imbalanced labels:\n",
        " # Resampling\n",
        " # Wieghted Loss\n",
        " # Data Augmentation: SMOTE method\n",
        " # Ensemble methods\n",
        " # Evaluation metrics: precision, recall, F1 socre, AUC-ROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uxQkQlKgjJq"
      },
      "source": [
        "# StringIndexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s7DAas8lgjes"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-------------+--------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+-----+---------------------+---------------+------------+\n",
            "|duration|protocol_type| service|flag|src_bytes|dst_bytes|land|wrong_fragment|urgent|host|num_failed_logins|logged_in|num_compromised|root_shell|su_attempted|num_root|num_file_creations|num_shells|num_access_files|num_outbound_cmds|is_host_login|is_guest_login|count|srv_count|serror_rate|srv_serror_rate|rerror_rate|srv_rerror_rate|same_srv_rate|diff_srv_rate|srv_diff_host_rate|dst_host_count|dst_host_srv_count|dst_host_same_srv_rate|dst_host_diff_srv_rate|dst_host_same_src_port_rate|dst_host_srv_diff_host_rate|dst_host_serror_rate|dst_host_srv_serror_rate|dst_host_rerror_rate|dst_host_srv_rerror_rate|connection_status|label|protocol_type_indexed|service_indexed|flag_indexed|\n",
            "+--------+-------------+--------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+-----+---------------------+---------------+------------+\n",
            "|       0|          tcp|ftp_data|  SF|     7233|        0|   0|             0|     0|   0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    8|        4|       0.00|           0.00|       0.00|           0.00|         0.50|         0.38|              0.00|           255|                10|                  0.04|                  0.34|                       0.04|                       0.00|                0.00|                    0.00|                0.00|                    0.00|          normal.|    0|                  1.0|            6.0|         0.0|\n",
            "|       0|          tcp| private| REJ|        0|        0|   0|             0|     0|   0|                0|        0|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|  137|        4|       0.00|           0.00|       1.00|           1.00|         0.03|         0.06|              0.00|           255|                 4|                  0.02|                  0.05|                       0.00|                       0.00|                0.00|                    0.00|                1.00|                    1.00|         neptune.|    1|                  1.0|            1.0|         2.0|\n",
            "|       0|         icmp|   ecr_i|  SF|     1032|        0|   0|             0|     0|   0|                0|        0|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|  250|      250|       0.00|           0.00|       0.00|           0.00|         1.00|         0.00|              0.00|           255|               255|                  1.00|                  0.00|                       1.00|                       0.00|                0.00|                    0.00|                0.00|                    0.00|           smurf.|    1|                  0.0|            0.0|         0.0|\n",
            "|       0|          tcp| private| REJ|        0|        0|   0|             0|     0|   0|                0|        0|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|   61|       10|       0.00|           0.00|       1.00|           1.00|         0.16|         0.08|              0.00|           255|                10|                  0.04|                  0.06|                       0.00|                       0.00|                0.00|                    0.00|                1.00|                    1.00|         neptune.|    1|                  1.0|            1.0|         2.0|\n",
            "|       0|          tcp|    http|  SF|      328|      535|   0|             0|     0|   0|                0|        1|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    6|        6|       0.00|           0.00|       0.00|           0.00|         1.00|         0.00|              0.00|           169|               255|                  1.00|                  0.00|                       0.01|                       0.03|                0.00|                    0.00|                0.00|                    0.00|          normal.|    0|                  1.0|            2.0|         0.0|\n",
            "+--------+-------------+--------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+-----+---------------------+---------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "columns_to_index = [\"protocol_type\", \"service\", \"flag\"]\n",
        "\n",
        "for column in columns_to_index:\n",
        "  indexer = StringIndexer(inputCol = column, outputCol = column + \"_indexed\")\n",
        "  df = indexer.fit(df).transform(df)\n",
        "\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA8dgldR92Vb"
      },
      "source": [
        "# Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PH-dAhB_97CC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-------------+-------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+-----+---------------------+---------------+------------+\n",
            "|duration|protocol_type|service|flag|src_bytes|dst_bytes|land|wrong_fragment|urgent|host|num_failed_logins|logged_in|num_compromised|root_shell|su_attempted|num_root|num_file_creations|num_shells|num_access_files|num_outbound_cmds|is_host_login|is_guest_login|count|srv_count|serror_rate|srv_serror_rate|rerror_rate|srv_rerror_rate|same_srv_rate|diff_srv_rate|srv_diff_host_rate|dst_host_count|dst_host_srv_count|dst_host_same_srv_rate|dst_host_diff_srv_rate|dst_host_same_src_port_rate|dst_host_srv_diff_host_rate|dst_host_serror_rate|dst_host_srv_serror_rate|dst_host_rerror_rate|dst_host_srv_rerror_rate|connection_status|label|protocol_type_indexed|service_indexed|flag_indexed|\n",
            "+--------+-------------+-------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+-----+---------------------+---------------+------------+\n",
            "|       0|            0|      0|   0|        0|        0|   0|             0|     0|   0|                0|        0|              0|         0|           0|       0|                 0|         0|               0|                0|            0|             0|    0|        0|          0|              0|          0|              0|            0|            0|                 0|             0|                 0|                     0|                     0|                          0|                          0|                   0|                       0|                   0|                       0|                0|    0|                    0|              0|           0|\n",
            "+--------+-------------+-------+----+---------+---------+----+--------------+------+----+-----------------+---------+---------------+----------+------------+--------+------------------+----------+----------------+-----------------+-------------+--------------+-----+---------+-----------+---------------+-----------+---------------+-------------+-------------+------------------+--------------+------------------+----------------------+----------------------+---------------------------+---------------------------+--------------------+------------------------+--------------------+------------------------+-----------------+-----+---------------------+---------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, sum\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
        "\n",
        "missing_values.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOP5yeTaCj4b"
      },
      "source": [
        "# To assess the linear separability of a feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tpfZeVqxChIk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 distribution: \n",
            "AVG src_bytes:  1157.047523592179\n",
            "STD src_bytes:  34226.1247180511\n",
            "Class 1 distribution: \n",
            "AVG src_bytes:  3483.7659517622237\n",
            "STD src_bytes:  1102603.8255053805\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import avg, stddev\n",
        "\n",
        "# avg & std for class 0\n",
        "class_0_stats = df.filter(df['label'] == 0).select(avg('src_bytes').alias(\"avg_src_bytes_0\"),\n",
        "                                                   stddev('src_bytes').alias(\"stddev_src_bytes_0\")).first()\n",
        "\n",
        "# avg & std for class 1\n",
        "class_1_stats = df.filter(df['label'] == 1).select(avg('src_bytes').alias(\"avg_src_bytes_1\"),\n",
        "                                                   stddev('src_bytes').alias(\"stddev_src_bytes_1\")).first()\n",
        "\n",
        "\n",
        "print(\"Class 0 distribution: \")\n",
        "print(\"AVG src_bytes: \", class_0_stats[\"avg_src_bytes_0\"])\n",
        "print(\"STD src_bytes: \", class_0_stats[\"stddev_src_bytes_0\"])\n",
        "\n",
        "print(\"Class 1 distribution: \")\n",
        "print(\"AVG src_bytes: \", class_1_stats[\"avg_src_bytes_1\"])\n",
        "print(\"STD src_bytes: \", class_1_stats[\"stddev_src_bytes_1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Awz_GCxon__"
      },
      "source": [
        "# VectorAssembler\n",
        "Prepare the features column (Use VectorAssembler to combine features into a single vector column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9iOAH4W1s_38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- duration: string (nullable = true)\n",
            " |-- protocol_type: string (nullable = true)\n",
            " |-- service: string (nullable = true)\n",
            " |-- flag: string (nullable = true)\n",
            " |-- src_bytes: string (nullable = true)\n",
            " |-- dst_bytes: string (nullable = true)\n",
            " |-- land: string (nullable = true)\n",
            " |-- wrong_fragment: string (nullable = true)\n",
            " |-- urgent: string (nullable = true)\n",
            " |-- host: string (nullable = true)\n",
            " |-- num_failed_logins: string (nullable = true)\n",
            " |-- logged_in: string (nullable = true)\n",
            " |-- num_compromised: string (nullable = true)\n",
            " |-- root_shell: string (nullable = true)\n",
            " |-- su_attempted: string (nullable = true)\n",
            " |-- num_root: string (nullable = true)\n",
            " |-- num_file_creations: string (nullable = true)\n",
            " |-- num_shells: string (nullable = true)\n",
            " |-- num_access_files: string (nullable = true)\n",
            " |-- num_outbound_cmds: string (nullable = true)\n",
            " |-- is_host_login: string (nullable = true)\n",
            " |-- is_guest_login: string (nullable = true)\n",
            " |-- count: string (nullable = true)\n",
            " |-- srv_count: string (nullable = true)\n",
            " |-- serror_rate: string (nullable = true)\n",
            " |-- srv_serror_rate: string (nullable = true)\n",
            " |-- rerror_rate: string (nullable = true)\n",
            " |-- srv_rerror_rate: string (nullable = true)\n",
            " |-- same_srv_rate: string (nullable = true)\n",
            " |-- diff_srv_rate: string (nullable = true)\n",
            " |-- srv_diff_host_rate: string (nullable = true)\n",
            " |-- dst_host_count: string (nullable = true)\n",
            " |-- dst_host_srv_count: string (nullable = true)\n",
            " |-- dst_host_same_srv_rate: string (nullable = true)\n",
            " |-- dst_host_diff_srv_rate: string (nullable = true)\n",
            " |-- dst_host_same_src_port_rate: string (nullable = true)\n",
            " |-- dst_host_srv_diff_host_rate: string (nullable = true)\n",
            " |-- dst_host_serror_rate: string (nullable = true)\n",
            " |-- dst_host_srv_serror_rate: string (nullable = true)\n",
            " |-- dst_host_rerror_rate: string (nullable = true)\n",
            " |-- dst_host_srv_rerror_rate: string (nullable = true)\n",
            " |-- connection_status: string (nullable = true)\n",
            " |-- label: integer (nullable = false)\n",
            " |-- protocol_type_indexed: double (nullable = false)\n",
            " |-- service_indexed: double (nullable = false)\n",
            " |-- flag_indexed: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "for column in df.columns:\n",
        "  df = df.withColumn(column, col(column).cast(\"double\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- duration: double (nullable = true)\n",
            " |-- protocol_type: double (nullable = true)\n",
            " |-- service: double (nullable = true)\n",
            " |-- flag: double (nullable = true)\n",
            " |-- src_bytes: double (nullable = true)\n",
            " |-- dst_bytes: double (nullable = true)\n",
            " |-- land: double (nullable = true)\n",
            " |-- wrong_fragment: double (nullable = true)\n",
            " |-- urgent: double (nullable = true)\n",
            " |-- host: double (nullable = true)\n",
            " |-- num_failed_logins: double (nullable = true)\n",
            " |-- logged_in: double (nullable = true)\n",
            " |-- num_compromised: double (nullable = true)\n",
            " |-- root_shell: double (nullable = true)\n",
            " |-- su_attempted: double (nullable = true)\n",
            " |-- num_root: double (nullable = true)\n",
            " |-- num_file_creations: double (nullable = true)\n",
            " |-- num_shells: double (nullable = true)\n",
            " |-- num_access_files: double (nullable = true)\n",
            " |-- num_outbound_cmds: double (nullable = true)\n",
            " |-- is_host_login: double (nullable = true)\n",
            " |-- is_guest_login: double (nullable = true)\n",
            " |-- count: double (nullable = true)\n",
            " |-- srv_count: double (nullable = true)\n",
            " |-- serror_rate: double (nullable = true)\n",
            " |-- srv_serror_rate: double (nullable = true)\n",
            " |-- rerror_rate: double (nullable = true)\n",
            " |-- srv_rerror_rate: double (nullable = true)\n",
            " |-- same_srv_rate: double (nullable = true)\n",
            " |-- diff_srv_rate: double (nullable = true)\n",
            " |-- srv_diff_host_rate: double (nullable = true)\n",
            " |-- dst_host_count: double (nullable = true)\n",
            " |-- dst_host_srv_count: double (nullable = true)\n",
            " |-- dst_host_same_srv_rate: double (nullable = true)\n",
            " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
            " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
            " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
            " |-- dst_host_serror_rate: double (nullable = true)\n",
            " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
            " |-- dst_host_rerror_rate: double (nullable = true)\n",
            " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
            " |-- connection_status: double (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- protocol_type_indexed: double (nullable = false)\n",
            " |-- service_indexed: double (nullable = false)\n",
            " |-- flag_indexed: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(28,[0,1,7,15,16,...|  0.0|\n",
            "|(28,[15,16,19,20,...|  1.0|\n",
            "|(28,[0,1,7,15,16,...|  0.0|\n",
            "|(28,[0,1,7,15,16,...|  0.0|\n",
            "|(28,[0,1,7,15,16,...|  0.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols = [\n",
        "        \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\",\n",
        "        \"host\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
        "        \"root_shell\", \"num_root\", \"num_file_creations\", \"num_shells\",\n",
        "        \"num_outbound_cmds\", \"is_host_login\", \"count\", \"srv_count\",\n",
        "        \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
        "        \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
        "        \"dst_host_srv_rerror_rate\",\n",
        "        \"protocol_type_indexed\", \"service_indexed\", \"flag_indexed\"\n",
        "        ],\n",
        "        outputCol = \"features\")\n",
        "\n",
        "data = assembler.transform(df)\n",
        "\n",
        "data = data.select('features', 'label')\n",
        "data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------+-----+\n",
            "|features                                                                                     |label|\n",
            "+---------------------------------------------------------------------------------------------+-----+\n",
            "|(28,[0,1,7,15,16,21,22,23,25,26],[247.0,395.0,1.0,2.0,2.0,17.0,255.0,1.0,1.0,2.0])           |0.0  |\n",
            "|(28,[15,16,19,20,21,22,23,24,25,26,27],[282.0,16.0,1.0,1.0,255.0,16.0,0.06,1.0,1.0,31.0,4.0])|1.0  |\n",
            "|(28,[0,1,7,15,16,21,22,23,24,25,26],[335.0,6718.0,1.0,3.0,56.0,66.0,255.0,1.0,0.01,1.0,2.0]) |0.0  |\n",
            "|(28,[0,1,7,15,16,21,22,23,25,26],[1078.0,335.0,1.0,1.0,1.0,77.0,143.0,0.55,1.0,3.0])         |0.0  |\n",
            "|(28,[0,1,7,15,16,21,22,23,25,26],[251.0,13356.0,1.0,12.0,15.0,255.0,255.0,1.0,1.0,2.0])      |0.0  |\n",
            "+---------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.show(5, truncate = False)\n",
        "\n",
        "#Sparse Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[219. 799.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.\n",
            "   0.  16.  17.   0.   0.   0.   0. 255. 255.   1.   0.   1.   2.   0.]\n",
            "[2.610e+02 3.913e+03 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 5.000e+00 5.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 2.550e+02 2.160e+02 8.500e-01 0.000e+00 1.000e+00 2.000e+00 0.000e+00]\n"
          ]
        }
      ],
      "source": [
        "# Extract the values from Sparse Vectors to the list format\n",
        "selected_data = data.select('features').limit(2).collect()\n",
        "\n",
        "for row in selected_data:\n",
        "  dense_vector = row[0].toArray()\n",
        "  print(dense_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# StandardScaler\n",
        "It is used to standardize a dataset along any axis. Standardization refers to scaling a set of values so that they have a mean of 0 and a standard deviation of 1 to normalize features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|scaledFeatures                                                                                                                                                                                                                                             |label|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|(28,[0,1,7,15,16,21,22,23,25,26],[2.4994482466720685E-4,0.011955205358076733,2.814168444874875,0.00938317749209615,0.008119426454581734,0.26256699554882135,2.40474301096007,2.4343873133173197,1.7373009114385578,0.5064219592776867])                    |0.0  |\n",
            "|(28,[15,16,19,20,21,22,23,24,25,26,27],[1.3230280263855572,0.06495541163665387,4.317351707362279,4.3076157788891996,3.9385049332323203,0.15088583598180833,0.14606323879903918,4.345175078220441,1.7373009114385578,7.849540368804145,6.695412657454234])  |1.0  |\n",
            "|(28,[0,1,7,15,16,21,22,23,24,25,26],[3.389939929696935E-4,0.20332929011534048,2.814168444874875,0.014074766238144226,0.22734394072828856,1.0193777474248358,2.40474301096007,2.4343873133173197,0.04345175078220441,1.7373009114385578,0.5064219592776867])|0.0  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler(inputCol = 'features', outputCol = 'scaledFeatures')\n",
        "\n",
        "scaler_model = scaler.fit(data)\n",
        "data = scaler_model.transform(data)\n",
        "\n",
        "data = data.select(\"scaledFeatures\", \"label\")\n",
        "data.show(3, truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Split data\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed = 1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPHCu_7R6Zg"
      },
      "source": [
        "# **Step 3:** Apply Logistic Regression model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoeQ-M6qw72A"
      },
      "source": [
        "Useful Parameters:\n",
        "\n",
        "**maxIter:** Specifies the maximum number of iterations (or epochs) for the optimization algorithm. It controls how many times the algorithm iterates to optimize the model parameters. The default value is 100.\n",
        "\n",
        "**regParam:** Controls the regularization parameter, which helps prevent overfitting by adding a penalty term to the loss function. A higher value of regParam increases the regularization strength. The default value is 0.0.\n",
        "\n",
        "**elasticNetParam:** Allows you to tune the balance between L1 and L2 regularization. A value of 0.0 corresponds to L2 regularization, 1.0 corresponds to L1 regularization, and any value in between represents a combination of both. The default value is 0.0.\n",
        "\n",
        "**threshold:** Sets the threshold for binary classification. Predicted probabilities above this threshold are classified as positive, while those below are classified as negative. The default value is 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mWs1zRdjR79w"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(featuresCol = \"scaledFeatures\", labelCol = 'label',\n",
        "                        threshold = 0.5, regParam = 0.01)\n",
        "\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "lr_predictions_train = lr_model.transform(train_data)\n",
        "lr_predictions_test = lr_model.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       0.0|\n",
            "+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_predictions_test.select(\"label\", \"prediction\").show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNvWtvJzSOz7"
      },
      "source": [
        "# **Step 4:** Evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Confusion Matrix**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MskcAZFxKr6Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+\n",
            "|label|prediction| count|\n",
            "+-----+----------+------+\n",
            "|  1.0|       1.0|116948|\n",
            "|  0.0|       1.0|   484|\n",
            "|  1.0|       0.0|  1303|\n",
            "|  0.0|       0.0| 28868|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "confusion_matrix = lr_predictions_test.groupBy(\"label\", \"prediction\").count()\n",
        "confusion_matrix.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>prediction</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>28868</td>\n",
              "      <td>484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1303</td>\n",
              "      <td>116948</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "prediction    0.0     1.0\n",
              "label                    \n",
              "0.0         28868     484\n",
              "1.0          1303  116948"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm_pandas = confusion_matrix.toPandas()\n",
        "cm_pandas.pivot(index = 'label', columns = 'prediction', values = 'count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Performance metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "tp = lr_predictions_test[(lr_predictions_test.label == 1) & (lr_predictions_test.prediction == 1)].count()\n",
        "fp = lr_predictions_test[(lr_predictions_test.label == 0) & (lr_predictions_test.prediction == 1)].count()\n",
        "fn = lr_predictions_test[(lr_predictions_test.label == 1) & (lr_predictions_test.prediction == 0)].count()\n",
        "tn = lr_predictions_test[(lr_predictions_test.label == 0) & (lr_predictions_test.prediction == 0)].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  98.79\n",
            "precision:  99.59\n",
            "recall:  98.9\n",
            "f1 score:  99.24\n"
          ]
        }
      ],
      "source": [
        "accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print('accuracy: ', round(accuracy, 4) * 100)\n",
        "print('precision: ', round(precision, 4) * 100)\n",
        "print('recall: ', round(recall, 4) * 100)\n",
        "print('f1 score: ', round(f1, 4) * 100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
