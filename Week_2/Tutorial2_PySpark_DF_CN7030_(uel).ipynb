{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjuAVgrxmIo3"
   },
   "source": [
    "# **Unlock the Potential of PySpark DataFrames: Hands-on Tips and Personalizations**\n",
    "\n",
    "`University of East London, Docklands Campus, 2023-24`\n",
    "\n",
    "`module name`: **`Machine Learning on Big Data (CN7030) - MSc AI&DS`**\n",
    "\n",
    "`Author`: **`Dr Amin Karami (PG Academic Lead in CDT School)`**\n",
    "\n",
    "`E`: **`a.karami@uel.ac.uk`**\n",
    "\n",
    "`W`: **`http://www.aminkarami.com/`**\n",
    "\n",
    "---\n",
    "\n",
    "**DataFrame (DF)**: Schema (named columns) + declarative language. A DataFrame is a Dataset organized into named columns. It is conceptually equivalent to a table in a relational database. It is very efficient for strucutred data.\n",
    "\n",
    "data: https://drive.google.com/file/d/1HiP_TkWYClAmzhhOFzhXdOXTfZb9DoB_/view?usp=drive_link (641MB)\n",
    "\n",
    "source: https://spark.apache.org/docs/latest/sql-programming-guide.html\n",
    "\n",
    "source: https://spark.apache.org/docs/latest/api/python/reference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSEJYGn6Byzu"
   },
   "source": [
    "# **Section 1: Initialize PySpark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T16:04:22.532711800Z",
     "start_time": "2024-02-12T16:04:10.269546100Z"
    },
    "id": "0LWTJaC8mHL5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\jaree\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\jaree\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkw8clYXax_k"
   },
   "source": [
    "# **System Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nIRRJNQkanIW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Memory: 18284122112 bytes\n",
      "Available Cores: 12\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Check available memory\n",
    "available_memory = psutil.virtual_memory().available\n",
    "print(f\"Available Memory: {available_memory} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Cores: 12\n"
     ]
    }
   ],
   "source": [
    "# Check available cores\n",
    "available_cores = psutil.cpu_count()\n",
    "print(f\"Available Cores: {available_cores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hxR5oWBc--l"
   },
   "source": [
    "# **Linking with Spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e3pTfRiwTMeY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.210.78.23:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tutorial2_CN7030</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1feaa294e90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linking with Spark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Tutorial2_CN7030\") \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "                    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "                    .config(\"spark.executor.cores\", \"2\") \\\n",
    "                    .config(\"spark.sql.inMemoryColumnarStorage.compressed\", \"true\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9zOJhv8beV5"
   },
   "source": [
    "# **Connect to the Google Drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfm3366qOMyk"
   },
   "source": [
    "# **Section 2: Create PySpark DataFrame from CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1n39Bv24XHjt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------+------------------+-----+------+------+------+--------+------+--------+\n",
      "|                  id|               age|salary|             score|sales|height|weight|gender|category|income|expenses|\n",
      "+--------------------+------------------+------+------------------+-----+------+------+------+--------+------+--------+\n",
      "|  0.8017532427858894| 79.71301351894658|     4| 37.10369234532471|   47|    62|     5|Female|       B|     8|      85|\n",
      "|  0.6565552949992319| 24.22600602366628|     6| 79.75769828959885|    8|    30|    42|  Male|       A|    70|      85|\n",
      "|  0.2515595782593636| 70.97364852287149|    17| 71.71375356646551|   82|     1|    72|  Male|       A|    66|      53|\n",
      "|  0.2073428376111074| 45.09378549789149|    32|              NULL|   59|    12|    21|  Male|       B|    56|       2|\n",
      "|  0.6392921379278927|30.357970527906065|    13|              NULL|   22|    69|    58|Female|       A|     0|      74|\n",
      "|  0.8505582285081454|              NULL|    14| 36.36958873390776|   16|    57|    51|Female|       B|    22|      52|\n",
      "|  0.8184715436384177|              NULL|    88|              NULL|   23|    54|    41|  Male|       B|    19|      27|\n",
      "|  0.7555506990689408| 57.94047153077633|    37| 99.05156945373632|   18|    67|    94|Female|       A|    91|      89|\n",
      "| 0.34380469538701885|              NULL|     0| 68.12994102604317|   50|    66|    29|Female|       A|    39|      10|\n",
      "| 0.07531261247891552| 78.00738662272417|    44|57.377461450339794|   32|    83|    68|  Male|       A|     3|      35|\n",
      "|  0.6520025939987977| 5.739474360847097|    60|              NULL|   69|    20|    59|Female|       A|    89|      94|\n",
      "|  0.6703304054828096| 82.09315695991832|    61| 86.30976835817982|   13|    64|     5|Female|       B|    30|      10|\n",
      "|   0.635481528615935|29.232534249025754|    33| 72.17303870051973|   19|    42|     5|Female|       A|     1|      11|\n",
      "|  0.6088087252200041| 46.04202629270567|    20| 82.62279087618317|   83|    39|    26|  Male|       A|    10|      58|\n",
      "|  0.9688522184233442|              NULL|    32|              NULL|   55|    88|    83|Female|       A|    98|      18|\n",
      "| 0.12847898035637806| 58.74807147974267|    41|25.651553478847266|   96|     0|     3|Female|       B|    36|      23|\n",
      "|  0.7095122526980591|              NULL|    69|              NULL|   72|    39|    97|  Male|       A|    88|      18|\n",
      "|0.054599328832547256|58.445521939730064|    84|29.619007900937078|   94|    72|    74|  Male|       A|    78|      87|\n",
      "|  0.8363451490970935| 9.267427535136319|    35|              NULL|   62|    16|    30|Female|       B|    13|      69|\n",
      "| 0.06476522637900317|              NULL|    47|              NULL|   78|    19|     4|Female|       B|    80|      23|\n",
      "+--------------------+------------------+------+------------------+-----+------+------+------+--------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- sales: integer (nullable = true)\n",
      " |-- height: integer (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- income: integer (nullable = true)\n",
      " |-- expenses: integer (nullable = true)\n",
      "\n",
      "10000000\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data.csv\", header = True, inferSchema = True)\n",
    "\n",
    "# show table\n",
    "df.show(truncate = True)\n",
    "\n",
    "# show schema\n",
    "df.printSchema()\n",
    "\n",
    "# some info\n",
    "print(df.count())\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFZJfbFyJbrr"
   },
   "source": [
    "# How many partitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aaB1cqUhJayf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBUU6lKRJ5_s"
   },
   "source": [
    "# Let's increase the number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eQ-wBuxDJy7V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase/Decrease the number of partitions from original\n",
    "df2 = df.repartition(8)\n",
    "# Reduce the number of partitions\n",
    "# df2 = df2.coalesce(1)\n",
    "df2.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df.repartition('category')\n",
    "df3.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJz7GJS2dVqk"
   },
   "source": [
    "# Write the DF to disk in a partitioned manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw-9D3g4dh4_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVjzSCVmnN7l"
   },
   "source": [
    "# **Section 3: DataFrame Operations and Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yglZp0fpnONc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0gtS4K6nhuH"
   },
   "source": [
    "# **Section 4: Working with Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kFKRxalnh_S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
